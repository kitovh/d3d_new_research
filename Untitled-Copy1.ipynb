{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f26e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "from scipy.cluster import hierarchy as hc\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sparse\n",
    "from random import sample\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import functions\n",
    "import scipy.io\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 20);\n",
    "\n",
    "## Data\n",
    "\n",
    "mat, data = functions.load_and_filter_data('/Users/kitovh/Documents/Research/PlasmaResearch/\\\n",
    "Cristina_Group/DIII_D_data/d3d-db-220420.mat', Filter=True)\n",
    "\n",
    "data = data[data.isna().apply(all)[data.isna().apply(all) == False].index]\n",
    "data['intentional_disruption'] = data['intentional_disruption'].fillna(-1)\n",
    "\n",
    "coverage = 100 * data.groupby('shot').apply(lambda x: x.count() / x.shape[0])\n",
    "coverage = coverage.mean()\n",
    "coverage = coverage[coverage >= 90]\n",
    "\n",
    "if 'time_until_disrupt' not in coverage.index:\n",
    "    columns = ['time_until_disrupt'] + list(coverage.index)\n",
    "    \n",
    "data = data[columns]\n",
    "\n",
    "shots = []\n",
    "for shot in tqdm(data.shot.unique()):\n",
    "    shot_data = data[data.shot == shot].copy()\n",
    "    shot_data_columns = [a for a in shot_data.columns if \n",
    "                          (a != 'intentional_disruption')\n",
    "                        & (a != 'time_until_disrupt')]\n",
    "    \n",
    "    shot_data = shot_data[shot_data_columns]\n",
    "    shot_coverage = 100 * (shot_data.count() / shot_data.shape[0])\n",
    "\n",
    "    if np.mean(shot_coverage) > 90:\n",
    "        shots.append(shot)\n",
    "data = data[data.shot.isin(shots)]\n",
    "\n",
    "filtered_data = []\n",
    "for shot in tqdm(data.shot.unique()):\n",
    "    df = data[data.shot == shot]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    df = df[df[df['dipprog_dt'] == df['dipprog_dt'].mode().values[0]].index[0]:]\n",
    "    filtered_data.append(df)\n",
    "\n",
    "data = pd.concat(filtered_data)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "bad_shots = []\n",
    "shots = []\n",
    "for i in tqdm(range(len(data.shot.unique()))):\n",
    "    df = data[data.shot == data.shot.unique()[i]]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    if np.abs(df['dipprog_dt']).min() < 1000:\n",
    "        shots.append(data.shot.unique()[i])\n",
    "    else:\n",
    "        bad_shots.append(data.shot.unique()[i])\n",
    "data = data[data.shot.isin(shots)]\n",
    "\n",
    "# shot = sample(shots, 1)[0]\n",
    "# df = data[data.shot == shot]\n",
    "\n",
    "# df['ip'].plot()\n",
    "\n",
    "og_data = data.copy()\n",
    "\n",
    "counts = data.groupby('shot')['time'].count()\n",
    "shots = counts[counts >= counts.mean()]\n",
    "data = data[data.shot.isin(shots.index)]\n",
    "\n",
    "comparison = data[['shot', 'time_until_disrupt']]\n",
    "comparison = comparison.groupby('shot').min()\n",
    "comparison['variable'] = ['disrupt' if a == 0 else 'no_disrupt' for a in comparison['time_until_disrupt']]\n",
    "comparison = comparison['variable'].reset_index()\n",
    "comparison = comparison[comparison.shot.isin(data.shot.unique())]\n",
    "\n",
    "# cols = [a for a in data if (a != 'time') & (a != 'shot') & (a != 'time_until_disrupt')]\n",
    "# data[cols] = (data[cols] - data[cols].mean()) / data[cols].std()\n",
    "\n",
    "# matplotlib.rcParams['figure.figsize'] = (20, 50);\n",
    "\n",
    "# shot_number = comparison[comparison.variable == 'disrupt'].shot.unique()[0]\n",
    "# fig, axs = plt.subplots(len(data.columns))\n",
    "# for i in range(len(data.columns)): \n",
    "#     axs[i].plot(data[data.shot == shot_number][data.columns[i]])\n",
    "#     axs[i].set_title(data.columns[i])\n",
    "# plt.show()\n",
    "\n",
    "# fig = plt.figure(figsize = (15, 20))\n",
    "# ax = fig.gca()\n",
    "# data.hist(ax=ax);\n",
    "\n",
    "training_non_disrupt = sample(list(comparison[comparison['variable'] == 'no_disrupt']['shot'].values), 200)\n",
    "training_disrupt = sample(list(comparison[comparison['variable'] == 'disrupt']['shot'].values), 650)\n",
    "\n",
    "training_data = data[data.shot.isin(training_non_disrupt) | data.shot.isin(training_disrupt)]\n",
    "\n",
    "testing_values = comparison[~comparison.shot.isin(training_data.shot.unique())]\n",
    "\n",
    "testing_non_disrupt = sample(list(testing_values[testing_values['variable'] == 'no_disrupt']['shot'].values), 10)\n",
    "testing_disrupt = sample(list(testing_values[testing_values['variable'] == 'disrupt']['shot'].values), 10)\n",
    "\n",
    "testing_data = data[data.shot.isin(testing_non_disrupt) | data.shot.isin(testing_disrupt)]\n",
    "\n",
    "# plt.plot(training_data[training_data.shot == training_data.shot.unique()[0]]['ip'].values)\n",
    "# plt.plot(training_data[training_data.shot == training_data.shot.unique()[1]]['ip'].values)\n",
    "# plt.plot(training_data[training_data.shot == training_data.shot.unique()[2]]['ip'].values)\n",
    "# plt.plot(training_data[training_data.shot == training_data.shot.unique()[3]]['ip'].values)\n",
    "# plt.plot(training_data[training_data.shot == training_data.shot.unique()[4]]['ip'].values)\n",
    "# plt.plot(training_data[training_data.shot == training_data.shot.unique()[5]]['ip'].values)\n",
    "# plt.plot(training_data[training_data.shot == training_data.shot.unique()[6]]['ip'].values)\n",
    "\n",
    "shot_numbers = training_non_disrupt + training_disrupt + testing_non_disrupt + testing_disrupt\n",
    "\n",
    "training_interpolated_data = []\n",
    "testing_interpolated_data = []\n",
    "\n",
    "for shot in tqdm(shot_numbers):\n",
    "    shot_data_backup = data[data['shot'] == shot]\n",
    "\n",
    "    granularity = 0.0001\n",
    "    x = np.arange(shot_data_backup['time'].min(), shot_data_backup['time'].max(), step=granularity)\n",
    "    x = x[x <= shot_data_backup['time'].max()]\n",
    "\n",
    "    features = [a for a in data.columns if \n",
    "                 (a != 'shot') & (a != 'time')\n",
    "               & (a != 'time_until_disrupt') & (a != 'other_hardware_failure')\n",
    "               & (a != 'power_supply_railed') & (a != 'intentional_disruption')]\n",
    "\n",
    "    interpolated = pd.DataFrame({'time':x})\n",
    "    for feature in features:\n",
    "        f1 = interp1d(shot_data_backup['time'], shot_data_backup[feature])\n",
    "        interpolated[feature] = f1(x)\n",
    "\n",
    "    interpolated = interpolated.rename(columns={'ip':'interpolated_ip'})\n",
    "    interpolated['shot'] = shot\n",
    "    \n",
    "    if shot in training_data.shot.unique():\n",
    "        training_interpolated_data.append(interpolated)\n",
    "        \n",
    "    elif shot in testing_data.shot.unique():\n",
    "        testing_interpolated_data.append(interpolated)\n",
    "\n",
    "offset = 0.04 / 0.0001\n",
    "print(offset)\n",
    "\n",
    "training_data = pd.concat(training_interpolated_data)\n",
    "testing_data = pd.concat(testing_interpolated_data)\n",
    "\n",
    "coverage_percent = (training_data.isna().sum() / training_data.shape[0]) * 100\n",
    "coverage_percent = coverage_percent[coverage_percent <= 5]\n",
    "\n",
    "training_data = training_data[coverage_percent.index]\n",
    "testing_data = testing_data[coverage_percent.index]\n",
    "\n",
    "training_data.set_index('shot', inplace=True)\n",
    "testing_data.set_index('shot', inplace=True)\n",
    "\n",
    "returned_training_data = []\n",
    "for shot in training_data.index.unique():\n",
    "    returned_training_data.append(training_data[training_data.index == shot].fillna(method='ffill'))\n",
    "    \n",
    "returned_testing_data = []\n",
    "for shot in testing_data.index.unique():\n",
    "    returned_testing_data.append(testing_data[testing_data.index == shot].fillna(method='ffill'))\n",
    "\n",
    "training_data = pd.concat(returned_training_data)\n",
    "testing_data = pd.concat(returned_testing_data)\n",
    "\n",
    "training_data.reset_index(inplace=True)\n",
    "testing_data.reset_index(inplace=True)\n",
    "\n",
    "training_data.dropna(inplace=True)\n",
    "testing_data.dropna(inplace=True)\n",
    "\n",
    "cols = [a for a in training_data if (a != 'time') & (a != 'shot')]\n",
    "cols = [\n",
    "    'Greenwald_fraction_RT', \n",
    "    'Te_HWHM', \n",
    "    'Wmhd_RT',        \n",
    "    'dipprog_dt_RT', \n",
    "    'interpolated_ip',\n",
    "    'ip_error_RT', \n",
    "    'ip_prog', \n",
    "    'kappa_area', \n",
    "    'n_e_RT', \n",
    "    'n_equal_1_normalized', \n",
    "    'p_rad', \n",
    "    'radiated_fraction', \n",
    "    'v_loop', \n",
    "    'zcur']\n",
    "cols = list(set(cols).intersection(training_data.columns))\n",
    "cols.sort()\n",
    "\n",
    "testing_data[cols] = (testing_data[cols] - training_data[cols].mean()) / training_data[cols].std()\n",
    "training_data[cols] = (training_data[cols] - training_data[cols].mean()) / training_data[cols].std()\n",
    "\n",
    "training_data['interpolated_ip'] = np.abs(training_data['interpolated_ip'])\n",
    "testing_data['interpolated_ip'] = np.abs(testing_data['interpolated_ip'])\n",
    "\n",
    "training_data = training_data[['shot', 'time'] + cols]\n",
    "testing_data = testing_data[['shot', 'time'] + cols]\n",
    "\n",
    "training_data['time'] = training_data.groupby('shot')['time'].apply(lambda x: x - x.values[0])\n",
    "testing_data['time'] = testing_data.groupby('shot')['time'].apply(lambda x: x - x.values[0])\n",
    "\n",
    "# matplotlib.rcParams['figure.figsize'] = (20, 50);\n",
    "\n",
    "# shot_number = training_disrupt[0]\n",
    "# fig, axs = plt.subplots(len(training_data.columns))\n",
    "# for i in range(len(training_data.columns)): \n",
    "#     axs[i].plot(training_data[training_data.shot == shot_number][training_data.columns[i]])\n",
    "#     axs[i].set_title(training_data.columns[i])\n",
    "# plt.show()\n",
    "\n",
    "# training_data = training_data.set_index('shot')\n",
    "# training_data = training_data.groupby('shot').shift(-40)\n",
    "# training_data.reset_index(inplace=True)\n",
    "\n",
    "training_data = training_data.set_index('shot')\n",
    "testing_data = testing_data.set_index('shot')\n",
    "\n",
    "# training_data.reset_index(inplace=True)\n",
    "# testing_data.reset_index(inplace=True)\n",
    "\n",
    "training_data.index = training_data.index / 100000\n",
    "testing_data.index = testing_data.index / 100000\n",
    "\n",
    "input_columns = ['time'] + cols\n",
    "output_columns = ['interpolated_ip']\n",
    "\n",
    "training_input = training_data[input_columns].groupby('shot').shift(offset)\n",
    "training_input.reset_index(inplace=True)\n",
    "\n",
    "training_output = training_data[output_columns].groupby('shot').shift(-offset)\n",
    "training_output.reset_index(inplace=True)\n",
    "\n",
    "training_input.dropna(inplace=True)\n",
    "training_output.dropna(inplace=True)\n",
    "\n",
    "testing_input = testing_data[input_columns].groupby('shot').shift(offset)\n",
    "testing_input.reset_index(inplace=True)\n",
    "\n",
    "testing_output = testing_data[output_columns].groupby('shot').shift(-offset)\n",
    "testing_output.reset_index(inplace=True)\n",
    "\n",
    "testing_input.dropna(inplace=True)\n",
    "testing_output.dropna(inplace=True)\n",
    "\n",
    "training_input = training_input[['shot'] + cols].values\n",
    "training_output = training_output.values\n",
    "\n",
    "testing_input = testing_input[['shot'] + cols].values\n",
    "testing_output = testing_output.values\n",
    "\n",
    "tmp = training_data.copy()\n",
    "tmp['index'] = np.arange(0, tmp.shape[0])\n",
    "tmp['shot'] = tmp.index\n",
    "\n",
    "training_indices = tmp[['shot', 'index']]\n",
    "training_indices.reset_index(drop=True, inplace=True)\n",
    "training_indices = training_indices.groupby('shot').index.max().values\n",
    "training_indices = np.insert(training_indices, 0, 0)\n",
    "\n",
    "tmp = testing_data.copy()\n",
    "tmp['index'] = np.arange(0, tmp.shape[0])\n",
    "tmp['shot'] = tmp.index\n",
    "\n",
    "testing_indices = tmp[['shot', 'index']]\n",
    "testing_indices.reset_index(drop=True, inplace=True)\n",
    "testing_indices = testing_indices.groupby('shot').index.max().values\n",
    "testing_indices = np.insert(testing_indices, 0, 0)\n",
    "\n",
    "## Reservoir\n",
    "\n",
    "def _update_state(A, W_in, state, inputs):\n",
    "    \"\"\"\n",
    "    Computes the next network states by applying the recurrent weights\n",
    "    to the last state & and feeding in the current input patterns\n",
    "    Following r(t+1) = tanh{A * r(t) + W_in * u(t)}\n",
    "        \n",
    "    Args:\n",
    "    ----\n",
    "        state: The preview states.\n",
    "        input_pattern: Next Intputs\n",
    "    \"\"\"\n",
    "    \n",
    "    preactivation = (np.dot(A, state) + np.dot(W_in, inputs))\n",
    "    NextState = np.tanh(preactivation)  \n",
    "    \n",
    "    return(NextState)\n",
    "\n",
    "ReservoirSize = 70\n",
    "AdjacentMatrixRadius = 0.0001\n",
    "Seed = 1\n",
    "\n",
    "np.random.seed(1234567)\n",
    "W = np.random.normal(scale=1e-1, size=(ReservoirSize, ReservoirSize))\n",
    "OriginalW = W.copy()\n",
    "\n",
    "G = nx.fast_gnp_random_graph(ReservoirSize, \n",
    "                             0.1, \n",
    "                             seed=12345)\n",
    "W = np.asarray([a * b for a, b in zip(W, nx.adjacency_matrix(G).toarray())])\n",
    "\n",
    "print(\"W Standard Deviation:\", np.std(W))\n",
    "radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
    "A = W.copy()\n",
    "A = A * AdjacentMatrixRadius / radius\n",
    "print('A Standard deviation:', np.std(A))\n",
    "\n",
    "values = []\n",
    "for i in range(len(G.degree)):\n",
    "    values.append(G.degree[i])\n",
    "print(\"Mean Degree:\", np.mean(values))\n",
    "print(\"Max Eigenval:\", np.max(np.abs(np.linalg.eigvals(A))))\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 10);\n",
    "plt.plot(A, 'o');\n",
    "\n",
    "# Initialize for states evolution\n",
    "np.random.seed(12345)\n",
    "W_in = np.random.normal(scale=1, size=(ReservoirSize, training_input.shape[1]-1))\n",
    "r_matrix = np.zeros((training_input.shape[0], ReservoirSize))\n",
    "\n",
    "# Evolve states matrix r. \n",
    "for t in tqdm(range(1, training_input.shape[0])):\n",
    "    r_matrix[t, :] = _update_state(\n",
    "        A=A, \n",
    "        W_in=W_in, \n",
    "        state=r_matrix[(t)], \n",
    "        inputs=training_input[(t-1), 1:]\n",
    "    )\n",
    "\n",
    "# plt.plot(r_matrix[:100000, 0])\n",
    "# plt.plot(r_matrix[100000:200000, 0]);\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.DataFrame(training_input)\n",
    "df = df.rename(columns={df.columns[0]:'shot'})\n",
    "df['index'] = np.arange(0, df.shape[0])\n",
    "\n",
    "indices_end = df.groupby('shot')['index'].last().values\n",
    "indices_start = df.groupby('shot')['index'].first().values\n",
    "len(indices_start)\n",
    "\n",
    "all_models = []\n",
    "predictions = []\n",
    "accuracy = [] \n",
    "true_values = []\n",
    "\n",
    "for i in tqdm(range(0, len(indices_start))):\n",
    "    start = indices_start[i] + 1\n",
    "    end = indices_end[i] + 1\n",
    "\n",
    "    model = linear_model.Ridge(alpha=0.01)\n",
    "    model.fit(\n",
    "        X=r_matrix[start:end],\n",
    "        y=training_output[start:end, 1:]\n",
    "    )\n",
    "    all_models.append(model)\n",
    "\n",
    "    prediction = model.predict(\n",
    "        r_matrix[start:end]\n",
    "    )\n",
    "    predictions.append(prediction)\n",
    "\n",
    "    true_values.append(\n",
    "        training_output[start:end, 1:]\n",
    "    )\n",
    "\n",
    "    accuracy.append(\n",
    "        mean_squared_error(\n",
    "            y_true=training_output[start:end, 1:], \n",
    "            y_pred=prediction\n",
    "        )\n",
    "    )\n",
    "\n",
    "# cols = ['time'] + cols\n",
    "\n",
    "m = 1\n",
    "for i in range(predictions[m].shape[1]):\n",
    "    plt.plot(predictions[m][:, i], label='pred')\n",
    "    plt.plot(true_values[m][:, i], label='true', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.title('ip')\n",
    "    plt.show();\n",
    "\n",
    "plt.hist(accuracy, bins=100);\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.DataFrame(testing_input)\n",
    "df = df.rename(columns={df.columns[0]:'shot'})\n",
    "df['shot'] = df['shot'] * 100000\n",
    "df['shot'] = df['shot'].astype(int)\n",
    "df['index'] = np.arange(0, df.shape[0])\n",
    "\n",
    "indices_end = df.groupby('shot')['index'].last().values\n",
    "indices_start = df.groupby('shot')['index'].first().values\n",
    "\n",
    "indices_start.sort()\n",
    "indices_end.sort()\n",
    "\n",
    "# indices_start = np.asarray(indices_start[:1].tolist() + indices_start[-1:].tolist())\n",
    "# indices_end = np.asarray(indices_end[:1].tolist() + indices_end[-1:].tolist())\n",
    "\n",
    "# indices_start = indices_start[-3:]\n",
    "# indices_end = indices_end[-3:]\n",
    "\n",
    "indices_start = [indices_start[0], indices_start[-1]]\n",
    "indices_end = [indices_start[0], indices_end[-1]]\n",
    "\n",
    "disrupt_errors = []\n",
    "disrupt_predictions = []\n",
    "disrupt_true_values = []\n",
    "\n",
    "non_disrupt_errors = []\n",
    "non_disrupt_predictions = []\n",
    "non_disrupt_true_values = []\n",
    "\n",
    "shot_numbers = []\n",
    "\n",
    "for s in tqdm(range(len(indices_start))):\n",
    "    start = indices_start[s] + 1\n",
    "    end = indices_end[s] + 1\n",
    "\n",
    "    shot_number = df[start:end]['shot'].unique()\n",
    "    assert len(shot_number) == 1, f\"shots are not unique for s={s}\"\n",
    "\n",
    "    x = r_matrix[-1]\n",
    "\n",
    "    states = []\n",
    "    data = testing_input[start:end, 1:]\n",
    "    for i in data:\n",
    "        x = _update_state(\n",
    "            A=A,\n",
    "            W_in=W_in,\n",
    "            state=x,\n",
    "            inputs=i\n",
    "        )\n",
    "        states.append(x)\n",
    "\n",
    "    state_prediction = []\n",
    "    for state in states:\n",
    "        model_predictions = []\n",
    "        for model in all_models:\n",
    "            model_predictions.append(\n",
    "                model.predict(state.reshape((1, -1)))\n",
    "            )\n",
    "        state_prediction.append(\n",
    "            np.mean(model_predictions, axis=0)\n",
    "        )\n",
    "    predictions = np.vstack(state_prediction)\n",
    "\n",
    "    score = mean_squared_error(\n",
    "                testing_output[start:end, 1:],\n",
    "                predictions, \n",
    "                multioutput='raw_values')\n",
    "    print(score)\n",
    "\n",
    "    if comparison[comparison.shot == shot_number[0]]['variable'].values[0] == 'disrupt':\n",
    "        disrupt_errors.append(\n",
    "           score\n",
    "        )\n",
    "        disrupt_predictions.append(\n",
    "            predictions\n",
    "        )\n",
    "        disrupt_true_values.append(\n",
    "            testing_output[start:end, 1:]\n",
    "        )\n",
    "        \n",
    "\n",
    "    if comparison[comparison.shot == shot_number[0]]['variable'].values[0] == 'no_disrupt':\n",
    "        non_disrupt_errors.append(\n",
    "           score\n",
    "        )\n",
    "        non_disrupt_predictions.append(\n",
    "            predictions\n",
    "        )\n",
    "        non_disrupt_true_values.append(\n",
    "            testing_output[start:end, 1:]\n",
    "        )\n",
    "\n",
    "print('disrupt mse: ', np.mean(disrupt_errors))\n",
    "\n",
    "print('non disrupt mse: ', np.mean(non_disrupt_errors))\n",
    "\n",
    "for i in range(len(disrupt_predictions)):\n",
    "    y_pred = pd.DataFrame(disrupt_predictions[i][:], columns=['ip'])\n",
    "    y_true = pd.DataFrame(disrupt_true_values[i][:], columns=['ip'])\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(y_pred, label='pred', color='red')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(y_true, label='true', color='blue')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6369d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "93244b6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(non_disrupt_predictions)):\n",
    "    y_pred = pd.DataFrame(non_disrupt_predictions[i], columns=['ip'])\n",
    "    y_true = pd.DataFrame(non_disrupt_true_values[i], columns=['ip'])\n",
    "\n",
    "    plt.plot(y_pred)\n",
    "    plt.plot(y_true)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a33f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398afe10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329a78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97055a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2f69a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c2f01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5744fec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15f9858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
